{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview: Free Trial Screener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of this experiment, Udacity courses currently have two options on the home page: \"start free trial\", and \"access course materials\". If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first. If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.\n",
    "\n",
    "In the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. [This screenshot](https://www.google.com/url?q=https://drive.google.com/a/knowlabs.com/file/d/0ByAfiG8HpNUMakVrS0s4cGN2TjQ/view?usp%3Dsharing&sa=D&usg=AFQjCNEGECoB6fS27szEfzRsLcsAWHVYkA) shows what the experiment looks like.\n",
    "\n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough timeâ€”without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n",
    "\n",
    "The unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Invariant metrics\n",
    "\n",
    "* Number of cookies\n",
    "* Number of clicks\n",
    "* Click through probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Check is useful when we want to make sure that the data filtered for experiment and control group is the same. This can be done using the right invariance metric. These three metrics shouldn't change because it's outside of the experiment, in a sense that these metric calculated all before the experiment begin.\n",
    "\n",
    "Number of cookies who views the page should be the same when Udacity experiment. They haven't click the \"Start Now\" button and see \"Free Trial Screener\" experiment. So number of cookies can be used as invariant metrics. When users click the button, they also haven't yet see the experiment that Udacity does, so number of clicks shouldn't change between experiment and control groups.\n",
    "\n",
    "Since the experiments only occurs ***after*** the users click the \"Start Now\" button, its click-through-probability also have to be the same for each experiment and control group. We know that number of cookies and number of clicks has to be the same, then click-thorough-probability also has to be the same.\n",
    "\n",
    "Besides cookie-id, there is also user-id. But user-id is not a good invariant, because Udacity also open to unregistered users to view page until after click of a button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "* Gross Conversion\n",
    "* Net Conversion\n",
    "\n",
    "For evaluation metrics, I choose Gross Conversion, Retention, and Net Conversion. All of these metrics are a good evaluation metrics since they change when the experiment change, and since each of the metrics has user-ids as the unit of analysis, should be much smaller standard error since Udacity also using it as the cookie of diversion. \n",
    "\n",
    "Gross conversion is the number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. After the visitors click the button, they should see the screener, hence the warning. It should be makes other visitors that doesn't have serious commitment back down and cancel it right away.\n",
    "\n",
    "Retention is number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout. The experiment intend to focus the visitors that only want to make a serious commitment. The retention rate should be higher for experiment group than the control group.\n",
    "\n",
    "Net conversion is number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. Net Conversion also true, since the experiment intend to see higher conversion rate for students to continue (at least make one payment) than the users that only click the button, that doesn't even see the warning experiment given.\n",
    "\n",
    "Ouf of these metrics, Retention turns out have a longer duration, which is 118 days. This takes too long, and it's not something Udacity willing to give for the experiment. So Retention will be excluded.\n",
    "\n",
    "I wouldn't expect too much from Net Conversion. The experiment only concern about the users serious in the free trial period. They want to feel experience and condition in the period. When past the 14-day boundary, it's not about commitment anymore. It could be financial issue, like visitors like me for example, that only want to experience it and indeed have a commitment. I want to pay later in the future, but want to have some validity whether this course is something that I would be benefit.\n",
    "\n",
    "So Gross Conversion is about the users that maybe want to try the condition in the free trial given, but could be having financial issue. This is something that free trial does. And Net Conversion is something that users have convinced about the commitment and financial, which is something that free trial does not do. So I will focus more with Gross Conversion than Net Conversion. I would expect these two metrics to move at the same direction for the reason that I mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate standard deviation, we use this formula\n",
    "\n",
    "```Python\n",
    "Formula = np.sqrt(p * (1-p) / n)\n",
    "```\n",
    "\n",
    "and using baseline data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baselines= \"\"\"Unique cookies to view page per day:\t40000\n",
    "Unique cookies to click \"Start free trial\" per day:\t3200\n",
    "Enrollments per day:\t660\n",
    "Click-through-probability on \"Start free trial\":\t0.08\n",
    "Probability of enrolling, given click:\t0.20625\n",
    "Probability of payment, given enroll:\t0.53\n",
    "Probability of payment, given click:\t0.1093125\"\"\"\n",
    "\n",
    "lines  = baselines.split('\\n')\n",
    "d_baseline = dict([(e.split(':\\t')[0],float(e.split(':\\t')[1])) for e in lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 5000 sample cookies instead of the original 40000, we can adjust accordingly using calculate probability. For these two evaluation metric, we need number of users who click \"Start Now\" button, and calculated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5000\n",
    "n_click = n * d_baseline['Click-through-probability on \"Start free trial\"']\n",
    "n_click"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, standard deviation for Gross conversion is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0202"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = d_baseline['Probability of enrolling, given click']\n",
    "round(np.sqrt(p * (1-p) / n_click),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for Net Conversion,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0156"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = d_baseline['Probability of payment, given click']\n",
    "round(np.sqrt(p * (1-p) / n_click),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Samples vs. Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using alpha = 0.05 and beta 0.2, and evaluation metrics as required:\n",
    "\n",
    "* Gross Conversion. Baseline: 0.20625 dmin: 0.01\n",
    "* Net Conversion. Baseline: 0.1093125 dmin: 0.0075\n",
    "\n",
    "We feed it into [sample size calculator](http://www.evanmiller.org/ab-testing/sample-size.html). \n",
    "\n",
    "What I get for each of the evaluation metric is:\n",
    "\n",
    "* Gross Conversion: 25.839 cookies who clicks.\n",
    "* Net Conversion: 27,411 cookies who clicks.\n",
    "\n",
    "We can use bigger number, so the minimum required cookies is sufficient. The sample size is only for one group, so output from the calculator must be doubled to get the enough pageviews. Since this only the user who clicks, we calculate number of pageviews using CTP. The pageviews needed then will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685275.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(27411 * 2) / d_baseline['Click-through-probability on \"Start free trial\"']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration of Exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraction of experiment exposure to Udacity visitors will be 80%. The experiment isn't risky enough that may potentially leaked as blog news or article. It doesn't really big a news, as Udacity only want to put little warning to the users. Because only 40000 pageviews each day can be gathered, the duration will be 22 days.\n",
    "\n",
    "This is where Retention metric fail for our evaluation metrics. It has a longer duration, which is 118 days. This takes too long, and it's not something Udacity willing to give for the experiment. So Retention will be excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do sanity checks to ensure that both experiment and control groups have equal proportion. It's the metric that shouldn't change when experiment change, which is invariant metrics that we chose earlier. First let's see the data that we want to analyze both at control and experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "control = pd.read_csv('control_data.csv')\n",
    "experiment = pd.read_csv('experiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0  Sat, Oct 11       7723     687          134        70\n",
       "1  Sun, Oct 12       9102     779          147        70\n",
       "2  Mon, Oct 13      10511     909          167        95\n",
       "3  Tue, Oct 14       9871     836          156       105\n",
       "4  Wed, Oct 15      10014     837          163        64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7716</td>\n",
       "      <td>686</td>\n",
       "      <td>105</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9288</td>\n",
       "      <td>785</td>\n",
       "      <td>116</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10480</td>\n",
       "      <td>884</td>\n",
       "      <td>145</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9867</td>\n",
       "      <td>827</td>\n",
       "      <td>138</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0  Sat, Oct 11       7716     686          105        34\n",
       "1  Sun, Oct 12       9288     785          116        91\n",
       "2  Mon, Oct 13      10480     884          145        79\n",
       "3  Tue, Oct 14       9867     827          138        92\n",
       "4  Wed, Oct 15       9793     832          140        94"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we count the total views and clicks for both control and experiment groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "control_views = control.Pageviews.sum()\n",
    "control_clicks = control.Clicks.sum()\n",
    "\n",
    "experiment_views = experiment.Pageviews.sum()\n",
    "experiment_clicks = experiment.Clicks.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For count like number of cookies and number of clicks in \"Start free trial\" button, we can do confidence interval around the fraction we expect in control group, and actual fraction as the observed outcome. Since we expect control and experiment to have equal proportion, we set the the expected proportion to be 0.5. Both invariant metrics, the confidence interval for sanity checks use the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanity_check_CI(control,experiment,expected):\n",
    "    SE = np.sqrt((expected*(1-expected))/(control + experiment))\n",
    "    ME = 1.96 * SE\n",
    "    return (expected-ME,expected+ME)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for sanity checks confidence interval of number of cookies who views the page,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49882039214902313, 0.50117960785097693)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_check_CI(control_views,experiment_views,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual proportion is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5006396668806133"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(control_views)/(control_views+experiment_views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that 0.5006 is within the interval, then experiment pass sanity checks for number of cookies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate confidence interval of number of clicks at \"Start free trial\" button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49588449572378945, 0.50411550427621055)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_check_CI(control_clicks,experiment_clicks,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the actual proportion,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5004673474066628"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(control_clicks)/(control_clicks+experiment_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again 0.5006 is within the interval, so our experiment also pass the sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our sanity check with ctp, is a little different calculation. Using simple count earlier, we know that if we setup our experiment in a proper way, the true proportion of control group should be 0.5. Since we don't know the true proportion of ctp control group, we build confidence interval around the control group, and ctp experiment as observed outcome. If the experiment change and ctp experiment is outside ctp control confidence interval, then our experiment failed sanity checks. Thus we can't continue our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctp_control = float(control_clicks)/control_views\n",
    "ctp_experiment = float(experiment_clicks)/experiment_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.0812103597525297</li>\n",
       "\t<li>0.0830412673966239</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.0812103597525297\n",
       "\\item 0.0830412673966239\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.0812103597525297\n",
       "2. 0.0830412673966239\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.08121036 0.08304127"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%R\n",
    "c = 28378\n",
    "n = 345543\n",
    "CL = 0.95\n",
    "\n",
    "pe = c/n\n",
    "SE = sqrt(pe*(1-pe)/n)\n",
    "z_star = round(qnorm((1-CL)/2,lower.tail=F),digits=2)\n",
    "ME = z_star * SE\n",
    "\n",
    "c(pe-ME, pe+ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.082125813574576823"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctp_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as you can see, click-through-probability of the experiment is still within the confidence interval of click-through-probability control groups. Since we have passed all of the sanity checks, we can continue to analyze the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Effect Size Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_gross = lambda group: float(group.dropna().Enrollments.sum())/ group.Clicks.sum()\n",
    "get_net = lambda group: float(group.dropna().Payments.sum())/ group.Clicks.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that observed_difference can be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_cont = 17293\n",
      "X_cont = 3785\n",
      "N_exp =  17260\n",
      "X_exp =  3423\n"
     ]
    }
   ],
   "source": [
    "print('N_cont = %i'%control.dropna().Clicks.sum())\n",
    "print('X_cont = %i'%control.dropna().Enrollments.sum())\n",
    "print('N_exp =  %i'%experiment.dropna().Clicks.sum())\n",
    "print('X_exp =  %i'%experiment.dropna().Enrollments.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.0291233583354044</li>\n",
       "\t<li>-0.0119863908253187</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.0291233583354044\n",
       "\\item -0.0119863908253187\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.0291233583354044\n",
       "2. -0.0119863908253187\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.02912336 -0.01198639"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%R\n",
    "\n",
    "N_cont = 17293\n",
    "X_cont = 3785\n",
    "N_exp = 17260\n",
    "X_exp = 3423\n",
    "\n",
    "observed_diff = X_exp/N_exp - X_cont/N_cont\n",
    "# print(observed_diff)\n",
    "p_pool = (X_cont+X_exp)/(N_cont+N_exp)\n",
    "SE = sqrt( (p_pool*(1-p_pool)) * ((1/N_cont) + (1/N_exp)))\n",
    "ME = 1.96 * SE\n",
    "# print(p_pool)\n",
    "c(observed_diff-ME, observed_diff+ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0205548745803616"
      ],
      "text/latex": [
       "0.0205548745803616"
      ],
      "text/markdown": [
       "0.0205548745803616"
      ],
      "text/plain": [
       "[1] 0.02055487"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed difference is outside the confidence interval. And the observed difference also above 0.01 dmin, minimum detectable effect. We should definitely launch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_cont = 17293\n",
      "X_cont = 2033\n",
      "N_exp =  17260\n",
      "X_exp =  1945\n"
     ]
    }
   ],
   "source": [
    "print('N_cont = %i'%control.dropna().Clicks.sum())\n",
    "print('X_cont = %i'%control.dropna().Payments.sum())\n",
    "print('N_exp =  %i'%experiment.dropna().Clicks.sum())\n",
    "print('X_exp =  %i'%experiment.dropna().Payments.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.0116046243598917</li>\n",
       "\t<li>0.00185717901080338</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.0116046243598917\n",
       "\\item 0.00185717901080338\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.0116046243598917\n",
       "2. 0.00185717901080338\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.011604624  0.001857179"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%R\n",
    "N_cont = 17293\n",
    "X_cont = 2033\n",
    "N_exp = 17260\n",
    "X_exp = 1945\n",
    "\n",
    "observed_diff = X_exp/N_exp - X_cont/N_cont\n",
    "# print(observed_diff)\n",
    "p_pool = (X_cont+X_exp)/(N_cont+N_exp)\n",
    "SE = sqrt( (p_pool*(1-p_pool)) * ((1/N_cont) + (1/N_exp)))\n",
    "ME = 1.96 * SE\n",
    "# print(p_pool)\n",
    "c(observed_diff-ME, observed_diff+ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "-0.00487372267454417"
      ],
      "text/latex": [
       "-0.00487372267454417"
      ],
      "text/markdown": [
       "-0.00487372267454417"
      ],
      "text/plain": [
       "[1] -0.004873723"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed difference is within the confidence interval so it's not statiscally significant and also not practically significant. We may fail or continue with our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign Test is also a test that must be confirmed with effect size test. I'm using [Online Calculator](http://graphpad.com/quickcalcs/binomial1.cfm) to calculate the  binomial p-value, whether the probability of experiment is higher than control groups. If we simulate it, what ar the odds. If the probability is so rare, that isn't likely due to chance, then the experiment succeed, provided significance level, which I choose to be 5%.\n",
    "\n",
    "I'm using helper function, to compare probability day-to-day whether the metric in question is smaller for group than the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_prob = lambda col: ((control.dropna()[col] / control.dropna().Clicks) <\n",
    "                            (experiment.dropna()[col]/experiment.dropna().Clicks))\n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the gross conversion, I got,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    19\n",
       "True      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prob('Enrollments').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    13\n",
       "True     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_prob('Payments').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I got p-value of 0.6776 for Net Conversion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would not use Benforreni correction in this case. Benforreni correction needs all metrics to be significantly different. This is not what we do in our experiment. We have one metric that need to be significant, and other metric that need to be insignificant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My recommendation is to launch the experiment. Gross conversion is all we need. Net Conversion fail, but since these two metrics are highly correlated and move at the same time, we don't need net conversion. And gross conversion is a great evaluation metric for free trial experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-Up Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IF Udacity indeed want to have only people who have commitment and financially ability to make at least one payment, then it brought down to only visitors who financially stable. We could separate those who financially can continue, compared to visitors who are committed hourly and financially. In other words, student who make at least one payment given they enrolling. This is something which Retention does.\n",
    "\n",
    "Udacity has Code Reviewer program. It gives reasonable payment per hour to whoever graduates reviewing the students' code. Udacity can launch an experiment that help this committed users but having financial issue. They will be in debt proceed after 14-day boundary and finished the program. But in return, they have to be Code Reviewer, and finish the debt through payroll. They won't be given any salary until their debt finished. Students who have financial issue, could be targeting Code Reviewer for their extra salary. Once their debt fulfilled, they can receive the salary. \n",
    "\n",
    "The Retention is a great evaluation metrics in this case, and we also can use other invariant metric in this experiment. Also a metric that calculate the number of user-ids become Code Reviewer, given that they checkout. The unit of diversion is user-ids. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
